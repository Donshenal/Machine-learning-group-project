{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model Notebook\n",
    "\n",
    "Goals of this notebook:\n",
    "* Given y_true, y_pred, calculate the RMSE\n",
    "* Implement a basic evaluation function\n",
    "* Assuming we are given X_train, y_train, fit a basic model and evaluate it\n",
    "* Additionally, implement cross_validation scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy -- TODO: Replace with actual data!!!\n",
    "X_train = [[7, 4, -1], [1, 1, -0.5], [0, 1, 1.5], [-1, -2.5, 5]]\n",
    "y_train = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a basic evaluation function\n",
    "def evaluate_rmse(y_true, y_pred, ndigits=3):\n",
    "    \"\"\" Prints the RMSE (root mean squared error) of y_pred in relation to y_true\"\"\"\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False )\n",
    "    print(\"Number of predictions: \", len(y_pred))\n",
    "    print(\"RMSE: \", round(rmse, ndigits))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  4\n",
      "RMSE:  0.612\n"
     ]
    }
   ],
   "source": [
    "# Test the evaluation function\n",
    "y_true_testing = [3, -0.5, 2, 7]\n",
    "y_pred_testing = [2.5, 0.0, 2, 8]\n",
    "#np.sqrt(sum((np.array(y_true_testing)-np.array(y_pred_testing))**2)/len(y_true_testing))\n",
    "assert float(np.abs(evaluate_rmse(y_true_testing, y_pred_testing) - 0.612)) <= 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we are given X_train, y_train, fit a basic linear model and evaluate it\n",
    "# TODO: need X_test, y_test\n",
    "# initialize the model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# train model \n",
    "lin_reg.fit(X_train,y_train)\n",
    "\n",
    "# make predictions on X_test\n",
    "y_predicted = lin_reg.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "error = evaluate_rmse(y_test, y_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ................................ score: (test=4.396) total time=   0.0s\n",
      "[CV] END ................................ score: (test=0.389) total time=   0.0s\n",
      "[CV] END ................................ score: (test=2.392) total time=   0.0s\n",
      "CV RMSE scores:  [4.39623629 0.38902621 2.39210155]\n"
     ]
    }
   ],
   "source": [
    "# Additionally, implement cross_validation scoring\n",
    "\n",
    "scorer_rmse = make_scorer(mean_squared_error, squared=False)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "# TODO: increase cv to 5?\n",
    "print(\"CV RMSE scores: \", cross_val_score(lr, X_train, y_train, cv=3, scoring=scorer_rmse, verbose=5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
