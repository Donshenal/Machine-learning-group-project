{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv(\"../data/wrangled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del final_data['date_caught']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select X and y features\n",
    "X = final_data.drop(['capture_number'], axis = 1)\n",
    "y = final_data['capture_number']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "# Check the shape of the data sets\n",
    "print(\"X_train:\", X_train.shape)  \n",
    "print(\"y_train:\", y_train.shape)  \n",
    "print(\"X_test:\", X_test.shape) \n",
    "print(\"y_test:\", y_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rmse(y_true, y_pred, ndigits=3):\n",
    "    \"\"\" Prints the RMSE (root mean squared error) of y_pred in relation to y_true\"\"\"\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False )\n",
    "    print(\"Number of predictions: \", len(y_pred))\n",
    "    print(\"RMSE: \", round(rmse, ndigits))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = CatBoostRegressor(n_estimators=20000,\n",
    "                            random_state = 42,\n",
    "                            objective='RMSE',\n",
    "                            #task_type = 'GPU',\n",
    "                            #bagging_temperature=0.1,\n",
    "                            l2_leaf_reg=5,\n",
    "                            depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the CatBoostRegressor\n",
    "catboost_model = CatBoostRegressor(iterations=10000, # Number of boosting iterations\n",
    "                            depth=6,                 # Depth of the trees\n",
    "                            learning_rate=0.1,       # Learning rate\n",
    "                            loss_function='RMSE',    # Loss function for regression\n",
    "                            verbose=100)             # Print progress every 100 iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred2 = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "error = evaluate_rmse(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "catboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = catboost_model.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "error = evaluate_rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost looks pretty good, hyperparameter-optimization with RandomizedSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'iterations': [100, 500, 1000, 10000],  # Number of boosting iterations\n",
    "    'learning_rate': [0.01, 0.1, 0.2],      # Learning rate\n",
    "    'depth': [6, 8, 10],                    # Depth of the trees\n",
    "    'l2_leaf_reg': [1, 3, 5],               # L2 regularization term\n",
    "    'border_count': [32, 64, 128],          # Number of splits for numerical features\n",
    "    'loss_function': ['RMSE'],              # Loss function for regression\n",
    "    'verbose': [100],                       # Print progress every 100 iterations\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "catboost_model = CatBoostRegressor()\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=catboost_model, param_distributions=param_grid, cv=5, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and estimator\n",
    "best_params = random_search.best_params_\n",
    "best_estimator = random_search.best_estimator_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_estimator.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "error = evaluate_rmse(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(y_test, y_pred):\n",
    "    \"\"\"Generated true vs. predicted values and residual scatter plot for models\n",
    "\n",
    "    Args:\n",
    "        y_test (array): true values for y_test\n",
    "        y_pred_test (array): predicted values of model for y_test\n",
    "    \"\"\"     \n",
    "    # Calculate residuals\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    # Plot real vs. predicted values \n",
    "    fig, ax = plt.subplots(1,2, figsize=(15, 5))\n",
    "    plt.subplots_adjust(right=1)\n",
    "    plt.suptitle('Error Analysis')\n",
    "    \n",
    "    ax[0].scatter(y_pred, y_test, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[0].plot([-400, 350], [-400, 350], color=\"#193251\")\n",
    "    ax[0].set_title(\"True vs. predicted values\", fontsize=16)\n",
    "    ax[0].set_xlabel(\"predicted values\")\n",
    "    ax[0].set_ylabel(\"true values\")\n",
    "    ax[0].set_xlim((y_pred.min()-10), (y_pred.max()+10))\n",
    "    ax[0].set_ylim((y_test.min()-40), (y_test.max()+40))\n",
    "    \n",
    "    ax[1].scatter(y_pred, residuals, color=\"#FF5A36\", alpha=0.7)\n",
    "    ax[1].plot([-400, 350], [0,0], color=\"#193251\")\n",
    "    ax[1].set_title(\"Residual Scatter Plot\", fontsize=16)\n",
    "    ax[1].set_xlabel(\"predicted values\")\n",
    "    ax[1].set_ylabel(\"residuals\")\n",
    "    ax[1].set_xlim((y_pred.min()-10), (y_pred.max()+10))\n",
    "    ax[1].set_ylim((residuals.min()-10), (residuals.max()+10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since\n",
    "\n",
    "Residual = Observed – Predicted\n",
    "\n",
    "…positive values for the residual (on the y-axis) mean the prediction was too low, and negative values mean the prediction was too high; 0 means the guess was exactly correct.\n",
    "\n",
    "Optimally the residuals,\n",
    "- (1) are pretty symmetrically distributed, tending to cluster towards the middle of the plot.\n",
    "- (2) they’re clustered around the lower single digits of the y-axis (e.g., 0.5 or 1.5, not 30 or 150).\n",
    "- (3) in general, there aren’t any clear patterns.\n",
    "\n",
    "\n",
    "-> This looks pretty good\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
