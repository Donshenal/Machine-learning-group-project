{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Set random seed \n",
    "RSEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "\n",
    "Support Vector Machines (SVM) can be used for regression tasks as well as classification tasks. When used for regression, it's often referred to as Support Vector Regression (SVR).\n",
    "\n",
    "The primary goal of SVR is to find a function that approximates the mapping from input variables to the continuous output variable in such a way that the margin of error or deviation (epsilon, ε) is minimized. The idea is to fit as many data points within a certain margin while minimizing the deviation of data points from the regression line.\n",
    "\n",
    "Key components of SVR for regression:\n",
    "\n",
    "    Kernel Trick: SVR, like SVM for classification, can use various kernel functions (e.g., linear, polynomial, radial basis function) to map the input data into a higher-dimensional feature space. The choice of kernel can have a significant impact on the model's performance.\n",
    "\n",
    "    Margin: SVR aims to minimize the deviation of data points from a decision boundary (often referred to as the epsilon-tube). The width of this tube is controlled by a hyperparameter, ε (epsilon). Data points falling within this tube are considered to have zero error.\n",
    "\n",
    "    Loss Function: SVR uses a loss function that penalizes data points based on their deviation from the regression line while allowing for a margin of error (ε). Common loss functions include the epsilon-insensitive loss and the squared ε-insensitive loss.\n",
    "\n",
    "    Regularization: Like SVM, SVR often includes a regularization parameter, typically denoted as C, which controls the trade-off between maximizing the margin and minimizing the loss. A smaller C encourages a wider margin but allows more errors, while a larger C penalizes errors more heavily.\n",
    "\n",
    "    Hyperparameter Tuning: The choice of kernel, kernel parameters, ε, and C are all hyperparameters that need to be tuned to optimize the SVR model for a specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv(\"data/wrangled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_data['date_caught']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12643, 40)\n",
      "y_train: (12643,)\n",
      "X_test: (5419, 40)\n",
      "y_test: (5419,)\n"
     ]
    }
   ],
   "source": [
    "# Select X and y features\n",
    "X = final_data.drop(['capture_number'], axis = 1)\n",
    "y = final_data['capture_number']\n",
    "\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "# Check the shape of the data sets\n",
    "print(\"X_train:\", X_train.shape)  \n",
    "print(\"y_train:\", y_train.shape)  \n",
    "print(\"X_test:\", X_test.shape) \n",
    "print(\"y_test:\", y_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (12643, 7)\n",
      "y_train: (12643,)\n",
      "X_test: (5419, 7)\n",
      "y_test: (5419,)\n"
     ]
    }
   ],
   "source": [
    "# Select X and y features\n",
    "X = final_data[['year_woy','capture_site','cs_category_0','cs_category_1','cs_category_2','cs_category_3','cs_category_4']\n",
    "                   \n",
    "]\n",
    "y = final_data['capture_number']\n",
    "\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True, stratify=y)\n",
    "\n",
    "# Check the shape of the data sets\n",
    "print(\"X_train:\", X_train.shape)  \n",
    "print(\"y_train:\", y_train.shape)  \n",
    "print(\"X_test:\", X_test.shape) \n",
    "print(\"y_test:\", y_test.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rmse(y_true, y_pred, ndigits=3):\n",
    "    \"\"\" Prints the RMSE (root mean squared error) of y_pred in relation to y_true\"\"\"\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False )\n",
    "    print(\"Number of predictions: \", len(y_pred))\n",
    "    print(\"RMSE: \", round(rmse, ndigits))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an SVR model\n",
    "svr = SVR(kernel='poly', C=1.0, epsilon=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR(epsilon=0.2, kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR(epsilon=0.2, kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR(epsilon=0.2, kernel='poly')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "svr.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = svr.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions:  5419\n",
      "RMSE:  4.106\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "error = evaluate_rmse(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look that good, makes sense to try out other models "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
